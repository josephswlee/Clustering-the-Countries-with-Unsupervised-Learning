---
title: "DS3001 Final Project"
author: "Joseph Lee (sl5nj), Iain Muir (iam9ez), Kent Williams (kbw3bb)"
date: "12/8/2021"
output:
  html_document:
    toc: TRUE
    theme: journal
    toc_float: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## PROJECT DESCRIPTION

**Objective:**  
To categorize the countries using socio-economic and health factors that determine the overall development of the country.

**Problem Statement:**  
HELP International have been able to raise around $ 10 million. Now the CEO of the NGO needs to decide how to use this money strategically and effectively. So, CEO has to make decision to choose the countries that are in the direst need of aid. Hence, your Job as a Data scientist is to categorize the countries using some socio-economic and health factors that determine the overall development of the country. Then you need to suggest the countries which the CEO needs to focus on the most.

**Context:**  
HELP International is an international humanitarian NGO that is committed to fighting poverty and providing the people of backward countries with basic amenities and relief during the time of disasters and natural calamities.

<center><img src="https://help-international.org/sites/all/themes/help/logo.png" alt="wine_beer" class="center" width="250">               <img src="https://upload.wikimedia.org/wikipedia/commons/7/7c/Kaggle_logo.png" alt="wine_beer" class="center" width="250"></center>


## DATA PREPARATION 
### Step 0 — Import Libraries
e1071, tidyverse, plotly, htmltools, devtools, caret, NbClust, reshape2, rvest, magrittr, stringr, cowplot, ggmap

```{r include=FALSE}
# Import necessary packages
library(e1071)
library(tidyverse)
library(plotly)
library(htmltools)
library(devtools)
library(caret)
library(NbClust)
library(reshape2)
library(rvest)
library(magrittr)
library(stringr)
# remotes::install_version("cowplot", "0.9.2")
library(cowplot)
# install.packages('ggmap')
library(ggmap)
```

```{r include=FALSE}
# Random Seed Value
SEED = 42
```

### Step 1 — Load Data

**DATA DICTIONARY**  
* **country**: Name of the country  
* **child_mort**: Death of children under 5 years of age per 1000 live births  
* **exports**: Exports of goods and services per capita. Given as %age of the GDP per capita  
* **health**: Total health spending per capita. Given as %age of GDP per capita  
* **imports**: Imports of goods and services per capita. Given as %age of the GDP per capita  
* **income**: Net income per person  
* **inflation**: The measurement of the annual growth rate of the Total GDP  
* **life_expec**: The average number of years a new born child would live if the current mortality patterns are to remain the same  
* **total_fer**: The number of children that would be born to each woman if the current age-fertility rates remain the same.  
* **gdpp**: The GDP per capita. Calculated as the Total GDP divided by the total population.  

```{r include=FALSE}
# Read csv, save a copy of the data set
data <- read_csv('Country-data.csv')
countries = data
```

**Peep First Five Rows**  
```{r echo=FALSE}
# Output First 5 Rows of Raw Data
head(countries)
```

**Data Dimensions**  
```{r echo=FALSE}
# Output Statistics Data Set Dimensions and Columns
cat('Shape:', dim(countries))
cat('Columns:', names(countries))
```

```{r echo=FALSE}
# Remove country names from the dataset, save as vector for visualization at the end
country_labels <- countries$country
countries <- countries[,-1]
cat("Country Labels:", paste(shQuote(country_labels[1:5]), collapse=", "), "...")
```

```{r include=FALSE}
# Save pre-normalized values
income_ <- countries$income
life_expec_ <- countries$life_expec
gdpp_ <- countries$gdpp
```

```{r include=FALSE}
# Output the Index of Columns for reference
column_index <- tibble(colnames(countries))
column_index
```

### Step 2 — Check for Missing Values
Our data set luckily does not have any missing values, so we can proceed without any worries that NULL values will hinder our model's performance  

```{r include=FALSE}
# Mising Values by Column
na_count <-sapply(countries, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count
```

```{r echo=FALSE}
# Total Missing Values
cat("Total Missing Values:", sum(na_count$na_count))
```

### Step 3 — Ensure Correct Data Types
In order to optimize the performance of our K-Means algorithm, we need to ensure that all variables are appropriately classified. There are no chr variables to convert to factors, considering we removed the country name for the actual training of the model.

```{r echo=FALSE}
# Output Data Set Structure
str(countries)
```

### Step 4 — Explore Data Distributions{.tabset}
We visualized the correlation between each variables to see the strength of the relationship between each variables. This will give us good indication how would our cluster partition data into groups, which are GDP, life expectancy, and income.  

Additionally, we wanted to plot the distributions of each variables to passively look for outliers and to better understand the data in general.  

#### Scatter Matrix  
```{r echo=FALSE}
# Plot a colored Scatter Matrix
plot(
  countries, 
  pch=20, 
  cex=1.5, 
  col="#69b3a2"
)
```

#### Histogram Matrix  
```{r echo=FALSE}
# Grid plot Histograms of each variable
p1 <- ggplot(countries, aes(x=child_mort)) + geom_histogram(bins=30)
p2 <- ggplot(countries, aes(x=exports)) + geom_histogram(bins=30)
p3 <- ggplot(countries, aes(x=health)) + geom_histogram(bins=30)
p4 <- ggplot(countries, aes(x=imports)) + geom_histogram(bins=30)
p5 <- ggplot(countries, aes(x=income)) + geom_histogram(bins=30)
p6 <- ggplot(countries, aes(x=inflation)) + geom_histogram(bins=30)
p7 <- ggplot(countries, aes(x=life_expec)) + geom_histogram(bins=30)
p8 <- ggplot(countries, aes(x=total_fer)) + geom_histogram(bins=30)
p9 <- ggplot(countries, aes(x=gdpp)) + geom_histogram(bins=30)
plot_grid(
  p1, p2, p3, p4, p5, p6, p7, p8, p9,
  label_size=12
)
```

#### Correlation Matrix  
```{r include=FALSE}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
}
reorder_cormat <- function(cormat){
    # Use correlation between variables as distance
    dd <- as.dist((1-cormat)/2)
    hc <- hclust(dd)
    cormat <-cormat[hc$order, hc$order]
}
```

```{r echo=FALSE}
# Reorder the correlation matrix
cormat <- round(cor(countries), 2)
cormat <- reorder_cormat(cormat)
upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Create a ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value)) +
     geom_tile(color = "white") +
     scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
       midpoint = 0, limit = c(-1,1), space = "Lab", 
        name="Pearson\nCorrelation") +
      theme_minimal()+ # minimal theme
     theme(axis.text.x = element_text(angle = 45, vjust = 1, 
        size = 12, hjust = 1)) +
     coord_fixed()
# Add Text
ggheatmap + 
geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
    theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      panel.grid.major = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      axis.ticks = element_blank(),
      legend.justification = c(1, 0),
      legend.position = c(0.6, 0.7),
      legend.direction = "horizontal")+
      guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                    title.position = "top", title.hjust = 0.5))
ggheatmap
```

### Step 5 — Normalize the Data
We implemented a MinMax Scaler to prepare the data set for the K-Means algorithm. Distance is the central mechanism in which K-Means clusters the data, and therefore we need to ensure everything is on the same scale.  

```{r include=FALSE}
# Min Max Scaler Function
normalize <- function(x){
 (x - min(x)) / (max(x) - min(x))
}
```

```{r include=FALSE}
# Subset Numeric Variables and Apply Normalize Function to Each Column
num_fields = names(select_if(countries, is.numeric))
countries[num_fields] <- as_tibble(lapply(countries[num_fields], normalize))
```

```{r echo=FALSE}
# Output First 5 Rows of Raw Data
head(countries)
```

## K-MEANS CLUSTERING
We decided to use K-Means Clustering because our goal is to categorize the countries using socio-economic and health factors that determine the overall development of the country.

Initially, we created K-means model with 2 centers because we expected the clusters will be divided into two groups: developed countries and underdeveloped countries. However, the variance explained was low at 0.3935. Before we are going to do hyperparameter tuning, we are first going to visualize our model to see how it looks.


### Step 6 — Initial K-Means Model
```{r include=FALSE}
# Set Random State Seed
set.seed(SEED)
```

```{r}
country_kmeans = kmeans(
  countries,
  centers=2,
  algorithm="Lloyd",
  iter.max=30
) 
```

```{r include=FALSE}
# Output K-Means Model Information
head(country_kmeans)
```

**Evaluate Cluster Quality**  
```{r echo=FALSE}
# ----- Evaluate the quality of the clustering -----
# Inter-cluster variance (betweenss): sum of the distances between points from different clusters.
num_= country_kmeans$betweenss
# Total variance (totss): sum of the distances between all the points in the data set.
denom_ = country_kmeans$totss
# Variance accounted for by clusters.
var_exp_ = num_ / denom_
cat('Variance Explained:', var_exp_)
```

```{r include=FALSE}
# Create Cluster Data set
clusters_ <- country_kmeans$cluster
cluster_df <- data.frame(
    country_labels, clusters_
)
cluster_df$clusters <- as.factor(cluster_df$clusters)
head(cluster_df)
```

### Step 7 — Visualize Clusters
The visualized socio-economic clusters looks great. But since it only has 2 clusters, it does not give us too much detail and result may look too generalized as the second cluster only had countries from Africa and some from Asia. We wanted to narrow down further to get better idea on which countries have the direst need for aid.  

**Load Map Data**  
```{r echo=FALSE}
# Load Map Data
map.world <- map_data("world")
head(map.world)
```

```{r include=FALSE}
# Recode Country Names to Align Between Files
map.world$region <- recode(
  map.world$region,
  'Antigua' = 'Antigua and Barbuda',
  'Republic of Congo' = 'Congo, Rep.',
  'Democratic Republic of the Congo' = 'Congo, Dem. Rep.',
  'Ivory Coast' = "Cote d'Ivoire",
  'Kyrgyzstan' = 'Kyrgyz Republic',
  'Laos' = 'Lao',
  'Micronesia' = 'Micronesia, Fed. Sts.',
  'North Macedonia' = 'Macedonia, FYR',
  'Slovakia' = 'Slovak Republic',
  'USA' = 'United States',
  'UK' = 'United Kingdom'
)
```

```{r include=FALSE}
# Join Map Data with Country Labels and Clusters
map.world_joined <- left_join(
    map.world, cluster_df, by=c('region' = 'country_labels')
)
map.world_joined <- map.world_joined %>% drop_na(clusters)
head(map.world_joined)
```

**Visualize Socio-Economic Clusters**  
```{r echo=FALSE}
# Plot World Map
ggplot() +
  geom_polygon(
      data=map.world_joined,
      aes(
        x=long, 
        y=lat, 
        group=group, 
        fill=clusters
      )
  ) +
  scale_fill_manual(values = c("#59bfff","#efb261")) +
  theme(
      text = element_text(family="Gill Sans", color="#000000"),
      axis.text = element_blank(),
      axis.title = element_blank(),
      axis.ticks = element_blank(),
      axis.line = element_blank()
  )
```

### Step 8 — Hyperparameter Tuning
We used few different metrics to determine the best number of clusters. Both from the elbow chart and NbClust gave us 3 as the best number of clusters to used. Therefore, we will be retrain the model with 3 centers.  

**Elbow Method**  
```{r include=FALSE}
# Function to Repeatedly Create K-Means Model with Different Numbers of Clusters
  # return: variance explained by the clusters for each k
explained_variance = function(data_in, k){
  
  # Running the K-Means algorithm.
  set.seed(SEED)
  
  kmeans_obj = kmeans(
    data_in, 
    centers=k,
    algorithm="Lloyd",
    iter.max=30
  )
  
  # Variance accounted for by clusters: intercluster variance / total variance
  var_exp = kmeans_obj$betweenss / kmeans_obj$totss
  var_exp  
}
explained_var_ = sapply(1:10, explained_variance, data_in=countries)
```

```{r echo=FALSE}
# Store Iterations x Explained Variance as a Data Frame
elbow = data.frame(k=1:10, explained_var_)
# Plot Scatter/Line Plot of the Explained Variance for each iteration
ggplot(elbow, 
       aes(x = k,  
           y = explained_var_)) + 
  geom_point(size = 4) +           
  geom_line(size = 1) +           
  xlab('k') + 
  ylab('Inter-Cluster Variance / Total Variance') + 
  theme_light()
```

**NbClust Method**  
```{r include=FALSE}
# Use NbClust to Select a Number of Clusters
nbclust_ = NbClust(
  data=countries, method="kmeans"
)
nbclust_
```

```{r echo=FALSE}
# Save Cluster Recommendations as a Data Frame
freq_k_ = nbclust_$Best.nc[1,]
freq_k_ = data.frame(freq_k_)
# Plot Histogram of Cluster Recommendations
ggplot(freq_k_,
       aes(x = freq_k_)) +
  geom_bar() +
  scale_x_continuous(breaks = seq(0, 15, by = 1)) +
  scale_y_continuous(breaks = seq(0, 12, by = 1)) +
  labs(x="Number of Clusters",
       y="Number of Votes",
       title = "Cluster Analysis")
```

### Step 9 — Final Model (k=3)
Variance explained has increased to 0.5479977, which is a lot better than the previous model (0.3935). We will visualized the clusters to the result to see if we need more tuning.  

The graph gives us more detail on breaking down the countries with their socio-economic status. However, it appears that the countries with lower socio-economic status remains the same (majority of them are from Africa and some Asia). Therefore, we determined that the output of the model would not improve any further with our current dataset and decided to use this as our final model. We will be visualize the model in 3D to determine the 10 countries that need the aids the most.  

```{r}
final_kmeans <- kmeans(
    countries, 
    centers=3,
    algorithm="Lloyd",
    iter.max=30
)
```

```{r include=FALSE}
# Output K-Means Model Information
head(final_kmeans)
```

**Evaluate Cluster Quality**  
```{r echo=FALSE}
# ----- Evaluate the quality of the clustering -----
# Inter-cluster variance (betweenss): sum of the distances between points from different clusters.
num_= final_kmeans$betweenss
# Total variance (totss): sum of the distances between all the points in the data set.
denom_ = final_kmeans$totss
# Variance accounted for by clusters.
var_exp_ = num_ / denom_
cat('Variance Explained:', var_exp_)
```

```{r include=FALSE}
# Create Cluster Data set
clusters_ <- final_kmeans$cluster
cluster_df <- data.frame(
    country_labels, clusters_
)
cluster_df$clusters <- as.factor(cluster_df$clusters)
head(cluster_df)
```

```{r include=FALSE}
# Join Map Data with Country Labels and Clusters
map.world_joined <- left_join(
    map.world, cluster_df, by=c('region' = 'country_labels')
)
map.world_joined <- map.world_joined %>% drop_na(clusters)
head(map.world_joined)
```

**Visualize Socio-Economic Clusters**  
```{r echo=FALSE}
# Plot World Map
ggplot() +
  geom_polygon(
      data=map.world_joined,
      aes(
        x=long, 
        y=lat, 
        group=group, 
        fill=clusters
      )
  ) +
  scale_fill_manual(values = c("#59bfff","#efb261", "#d3d3d3")) +
  theme(
      text = element_text(family="Gill Sans", color="#000000"),
      axis.text = element_blank(),
      axis.title = element_blank(),
      axis.ticks = element_blank(),
      axis.line = element_blank()
  )
```

### Step 10 — Visualize 3D Clusters
In order to further visualize the K-Means clusters, we used plotly to create a 3D visual on the basis of income, life expectancy, and GDP per Capita. As brielfy mentioned before, these variables highly correlated to each other and clearly illustrate the breakdown of the clusters. The purple data points represent more underdeveloped nations, the orange represents developing nations, and the green represents the developed nations. Beyond correlation, our group thought these variables made the most sense considering each's importance to a nation's wellbeing.  

```{r include=FALSE}
# Add Clusters as Factor Column to Data Set
clusters = as.factor(final_kmeans$cluster)
countries$clusters <- clusters
# Add back country names and pre-normalized values
countries$country <- country_labels
countries$income_ <- income_
countries$life_expec_ <- life_expec_
countries$gdpp_ <- gdpp_
```

```{r echo=FALSE}
# Plot 3D Scatter Plot (X=MP, Y=PTS, Z=AST) using Plotly
fig <- plot_ly(
    countries,
    type = "scatter3d",
    mode="markers",
    symbol = ~clusters,
    x = ~income_,
    y = ~life_expec_,
    z = ~gdpp_,
    color = ~clusters,
    text = ~paste('Country:', country,
                  "\nIncome:", income_,
                  "\nLife Expectancy", life_expec_,
                  "\nGDP Per Capita", gdpp_)
)
fig
```

## CONCLUSION
In conclusion, the 10 countries that need the direst need of aid we selected are: Haiti, Central African Republic, Lesotho, Malawi, Zambia, Mozambique, Sierra Leone, Guinea-Bissau, Afghanistan, and Uganda. These countries have the lowest net income per person, life expectancy, and the GDP per capita; furthermore, as made evident by the graph above, they are all in the underdeveloped cluster.  

Our K-Means model performed pretty well and was able to capture distinct clusters of nations. Furthermore, the consensus of three clusters for the final model makes a lot of sense, as nations can generally be classified as underdeveloped, developing, or developed. Although the explained variance of our model wasn't incredibly high, this is expedited for a limited number of clusters as the model is grouping continents of countries and countries that are on completely opposite ends of the Earth. In order to effectively maximize the explainced variance of our model, we would need to significantly increase the number of clusers; this would inevitably lead to overfitting and an unnecessary amount of complexity in the model.   

Overall, we are happy with the model's performance and believe it definitely provides a lot of value. Recognizing and visualizing the disparity in the wellbeing of nations is a necessary step to providing aid. 

## FAIRNESS ASSESSMENT
Our data set does not include any protected classes and therefore we will not be conducting a fairness assessment. That being said, it is important to note that each country inherently has a wide variety of demographic information.  

## FUTURE WORK
While we were building the model, we factored in net income per person, life expectancy, and the GDP per capita as the vital variables in deciding a socio-economic status of a country. However, there might be other variables that might be considered more important. Furthermore, even though we computed ten countries with the direst need of aid, we still need to dig further into which areas HELP International wants to focus on more. For example, those selected countries have areas of problems that must be prioritized, and aid cannot be blindly given to them. Therefore, further analysis on researching which area those countries need to be aided on should be conducted next.   

Additionally, attempting to build a variety of unsupervised learning algorithms might have proved to produce better results. Although K-Means is likely one of the best algorithms for a clustering problem like this, there are definitely multiple other options. For example, algorithms like DBSCAN could potentially work as well.  

Lastly, we definitely could benefit from more data for training. Yet, unlike many other machine learning problems where more data could be collected, there are a finite number of countries that can be used at data points. Therefore, we could experiment with feature engineering with the existing columns, or look for different features all together that we believe are relevant to the wellbeing of a country.  


## REFERENCES{.tabset}

### Dataset
* [Kaggle](https://www.kaggle.com/)  
* [Unsupervised Learning on Country Data](https://www.kaggle.com/rohan0301/unsupervised-learning-on-country-data?select=data-dictionary.csv)

### Code Snippets
* [Correlation Matrix](http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization)  
* [World Plot](https://www.sharpsightlabs.com/blog/map-talent-competitiveness/)  
* [Stack Overflow](https://stackoverflow.com/)  


## AUTHORS{.tabset}

### Joseph Lee 
* E: sl5nj@virginia.edu  
* [GitHub](https://github.com/josephswlee)  
* [LinkedIn](https://www.linkedin.com/in/lee-sangwoo/)  

### Iain Muir
* E: iam9ez@virginia.edu  
* [GitHub](https://github.com/iainmuir6)  
* [LinkedIn](https://www.linkedin.com/in/iain-a-muir/)  

### Kent Williams
* E: kbw3bb@virginia.edu  
* [GitHub](https://github.com/kbw3bb)  
* [LinkedIn](https://www.linkedin.com/in/kent-williams-/) 